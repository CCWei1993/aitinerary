{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS.dat\n",
    "### synonym.dat\n",
    "### word2vec.model\n",
    "### spot_clf.joblib\n",
    "### weight.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/93/c6011037f24e3106d13f3be55297bf84ece2bf15b278cc4776339dc52db5/gensim-3.8.1-cp37-cp37m-manylinux1_x86_64.whl (24.2MB)\n",
      "\u001b[K     |████████████████████████████████| 24.2MB 2.9MB/s eta 0:00:01                               | 686kB 2.9MB/s eta 0:00:098        | 5.7MB 2.9MB/s eta 0:00:07.9MB/s eta 0:00:06:00:05�█▉             | 14.3MB 2.9MB/s eta 0:00:04██████████████████████          | 16.6MB 2.9MB/s eta 0:00:03MB 2.9MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.12.0)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/09/735f2786dfac9bbf39d244ce75c0313d27d4962e71e0774750dc809f2395/smart_open-1.9.0.tar.gz (70kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 25.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.17.2)\n",
      "Collecting boto>=2.32 (from smart-open>=1.8.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/10/c0b78c27298029e4454a472a1919bde20cb182dab1662cec7f2ca1dcc523/boto-2.49.0-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 35.8MB/s eta 0:00:010:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Collecting boto3 (from smart-open>=1.8.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/80/43311e9948169a65168cb9ce7eabf66d013c0ec099d4e2c3b72bd65eabbc/boto3-1.10.25-py2.py3-none-any.whl (128kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 58.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Collecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.8.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/83/94/7179c3832a6d45b266ddb2aac329e101367fbdb11f425f13771d27f225bb/jmespath-0.9.4-py2.py3-none-any.whl\n",
      "Collecting s3transfer<0.3.0,>=0.2.0 (from boto3->smart-open>=1.8.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/8a/1fc3dba0c4923c2a76e1ff0d52b305c44606da63f718d14d3231e21c51b0/s3transfer-0.2.1-py2.py3-none-any.whl (70kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 26.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting botocore<1.14.0,>=1.13.25 (from boto3->smart-open>=1.8.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/93/8a592d3be76ef6b9dba1c97b0139a0b2cabf4185692fd5c4938feea71d85/botocore-1.13.25-py2.py3-none-any.whl (5.6MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6MB 40.7MB/s eta 0:00:01     | 1.3MB 40.7MB/s eta 0:00:01�████████████████████████████▏| 5.4MB 40.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /opt/conda/lib/python3.7/site-packages (from botocore<1.14.0,>=1.13.25->boto3->smart-open>=1.8.1->gensim) (2.8.0)\n",
      "Collecting docutils<0.16,>=0.10 (from botocore<1.14.0,>=1.13.25->boto3->smart-open>=1.8.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cd/a6aa959dca619918ccb55023b4cb151949c64d4d5d55b3f4ffd7eee0c6e8/docutils-0.15.2-py3-none-any.whl (547kB)\n",
      "\u001b[K     |████████████████████████████████| 552kB 54.5MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for smart-open: filename=smart_open-1.9.0-cp37-none-any.whl size=73088 sha256=159c9cacc4f6fd7332376c163e08c5c1047cd5a1e8a7914de2fd05c67bf6f2d6\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/ab/10/93/5cff86f5b721d77edaecc29959b1c60d894be1f66d91407d28\n",
      "Successfully built smart-open\n",
      "Installing collected packages: boto, jmespath, docutils, botocore, s3transfer, boto3, smart-open, gensim\n",
      "Successfully installed boto-2.49.0 boto3-1.10.25 botocore-1.13.25 docutils-0.15.2 gensim-3.8.1 jmespath-0.9.4 s3transfer-0.2.1 smart-open-1.9.0\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5007/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [22/Nov/2019 01:38:12] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such word in vocabulary\n",
      "No such word in vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2019 01:38:44] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such word in vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2019 01:48:42] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2019 01:48:48] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2019 03:45:21] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Nov/2019 03:50:15] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2019 03:50:21] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2019 03:50:28] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2019 03:50:36] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Nov/2019 03:50:42] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2019 03:50:47] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2019 03:50:52] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2019 03:50:58] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such word in vocabulary\n",
      "No such word in vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2019 03:51:04] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2019 03:51:09] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2019 04:06:15] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Nov/2019 04:06:59] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such word in vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2019 04:47:48] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2019 04:48:53] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Nov/2019 04:49:00] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2019 04:49:07] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2019 04:49:14] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Nov/2019 04:49:22] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2019 04:49:29] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2019 04:49:36] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2019 04:49:43] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2019 04:49:50] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2019 04:49:57] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2019 04:50:05] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2019 04:50:12] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2019 04:50:20] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2019 04:50:27] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2019 04:50:35] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2019 05:48:39] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Nov/2019 05:48:44] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such word in vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2019 05:48:50] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such word in vocabulary\n",
      "No such word in vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2019 05:54:37] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such word in vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2019 08:49:14] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such word in vocabulary\n",
      "No such word in vocabulary\n",
      "No such word in vocabulary\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n",
    "from flask import Flask\n",
    "import flask\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "import joblib \n",
    "import numpy as np\n",
    "import random\n",
    "from gensim.models import word2vec\n",
    "import pickle\n",
    "\n",
    "def countScore(df_tag,name,manner):\n",
    "    if sum((df_tag.loc[:,'name']==name) & (df_tag.loc[:,'tag']==manner)):\n",
    "        return weight_spot.loc[0,manner]\n",
    "    else: \n",
    "        return 0\n",
    "\n",
    "def showResult(result):\n",
    "    if len(result)>0:\n",
    "        columns=list(result[0].keys())\n",
    "        return pd.DataFrame(result,columns=columns)\n",
    "    else:\n",
    "        return None\n",
    "def getSpot(DF):\n",
    "    score=DF['score'].to_numpy()\n",
    "    name=DF['name'].to_numpy()\n",
    "    weightList=[-1]\n",
    "    cumSum=0\n",
    "    for sc in score:\n",
    "        cumSum+=sc\n",
    "        weightList.append(cumSum)\n",
    "    randNum=random.randint(0,weightList[-1])\n",
    "    index=0\n",
    "    for i in range(len(weightList)-1):\n",
    "        if weightList[i]< randNum and randNum <= weightList[i+1]:\n",
    "            index=i\n",
    "            break\n",
    "    return name[index]\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "@app.route(\"/\",methods=[\"POST\"])\n",
    "def recommend():\n",
    "    \n",
    "    if flask.request.method == \"POST\":\n",
    "        userdata=flask.request.json\n",
    "    # query data from mysql\n",
    "    connection = pymysql.connect(host='mysql',\n",
    "                                 user='root',\n",
    "                                 password='iii',\n",
    "                                 charset='utf8mb4',\n",
    "                                 database='test',\n",
    "                                 cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "    try:\n",
    "        with connection.cursor() as cursor:       \n",
    "            sql_query = '''\n",
    "                        SELECT *\n",
    "                        FROM `tag`\n",
    "                        '''\n",
    "            cursor.execute(sql_query)\n",
    "            result = cursor.fetchall()\n",
    "            df_tag=showResult(result)\n",
    "\n",
    "            sql_query = '''\n",
    "                        SELECT *\n",
    "                        FROM `spot` \n",
    "                        '''\n",
    "            cursor.execute(sql_query)\n",
    "            result = cursor.fetchall()\n",
    "            df_spot=showResult(result)\n",
    "    finally:\n",
    "        connection.close()\n",
    "    \n",
    "\n",
    "    # if crampedSechedule 4 spots per day else 3 spots per day\n",
    "    input_data=[userdata['age'],userdata['been2tko'],userdata['howlong'],userdata['budget'],userdata['isFemale']]\n",
    "    cluster=clf.predict(np.array(input_data).reshape((1,-1)))[0]\n",
    "\n",
    "    df_spot['score']=0.5 \n",
    "    items=['淺草','迪士尼','晴空塔','東京鐵塔',\n",
    "                     '秋葉原','明治神宮','築地外圍海鮮市場','豐洲市場',\n",
    "                     '原宿竹下通','台場','大江戶物語','六本木之丘展望台',\n",
    "                     '新宿歌舞伎町','阿美橫丁','上野',\n",
    "                     '神田萬世橋']\n",
    "\n",
    "    spotsPerDay=4 if userdata['crampedSechedule'] else 3\n",
    "    itinerary=[] \n",
    "    df_spot['chosen']=False\n",
    "    for item in items: \n",
    "        df_spot['score']+=df_spot['name'].apply(lambda x: weight_spot.loc[0,item] if item in x else 0)\n",
    "    df_spot['score']+=df_spot['child'].apply(lambda x: userdata['with_child'] if x>=0.073091 else 0)\n",
    "    df_spot['score']+=df_spot['name'].apply(lambda n:countScore(df_tag,n,'自然景觀'))\n",
    "    df_spot['score']+=df_spot['name'].apply(lambda n:countScore(df_tag,n,'購物'))\n",
    "    df_spot['score']=df_spot['score']**df_spot['score']\n",
    "\n",
    "    df_spot['score']=(df_spot['score']).apply(lambda x : int(x*100))\n",
    "    # df_spot.sort_values(by='score', ascending=False)\n",
    "\n",
    "    mustGo=[]\n",
    "    if cluster==0:\n",
    "        if random.choices([True,False], weights=[0.5625,1-0.5625])[0]:\n",
    "            mustGo.append('淺草 Asakusa')\n",
    "        if random.choices([True,False], weights=[0.437500,1-0.437500])[0]:\n",
    "            mustGo.append('築地市場 Tsukiji Jogaii Market')\n",
    "        if random.choices([True,False], weights=[0.437500,1-0.437500])[0]:\n",
    "            mustGo.append(random.choice(['東京迪士尼樂園 Tokyo Disneyland','東京迪士尼海洋樂園 Tokyo DisneySea']))\n",
    "    elif cluster==1:\n",
    "        if random.choices([True,False], weights=[0.602941,1-0.602941])[0]:\n",
    "            mustGo.append('淺草 Asakusa')\n",
    "        if random.choices([True,False], weights=[0.661765,1-0.661765])[0]:\n",
    "            mustGo.append(random.choice(['東京迪士尼樂園 Tokyo Disneyland','東京迪士尼海洋樂園 Tokyo DisneySea']))    \n",
    "    else:\n",
    "        if random.choices([True,False], weights=[0.690909,1-0.690909])[0]:\n",
    "            mustGo.append('淺草 Asakusa')\n",
    "        if random.choices([True,False], weights=[0.527273,1-0.527273])[0]:\n",
    "            mustGo.append(random.choice(['東京迪士尼樂園 Tokyo Disneyland','東京迪士尼海洋樂園 Tokyo DisneySea']))        \n",
    "\n",
    "    for spot in mustGo:\n",
    "\n",
    "        interesting_word=spot.split(' ')[0]\n",
    "        df_spot.loc[df_spot['name']==spot,'chosen']=True\n",
    "        itinerary.append(df_spot.loc[df_spot['name']==spot,:])\n",
    "        if '迪士尼' in spot:\n",
    "            continue\n",
    "        try:\n",
    "            related_spot=[]\n",
    "            for word in model.wv.similar_by_word(interesting_word,100):\n",
    "                if 'N' in pos[word[0]] or 'n' in pos[word[0]]:\n",
    "                    if word[1]>0.65:\n",
    "                        if word[0] in synonym.keys():\n",
    "                            related_spot.append(synonym[word[0]])\n",
    "                        else:\n",
    "                            related_spot.append(word[0])\n",
    "    #         print(related_spot)\n",
    "            for rs in related_spot:\n",
    "                searchbool=df_spot['name'].apply(lambda s: True if rs in s else False)\n",
    "                chosen=df_spot.loc[searchbool & (df_spot['chosen']==False),'name'].to_numpy()\n",
    "                if len(chosen)==0:\n",
    "                    continue\n",
    "                df_spot.loc[df_spot['name']==chosen[0],'chosen']=True\n",
    "                tmp=df_spot.loc[df_spot['name']==chosen[0]]\n",
    "\n",
    "                itinerary[-1]=itinerary[-1].append(tmp, ignore_index=True)\n",
    "                if itinerary[-1].shape[0]>=spotsPerDay:\n",
    "                    break\n",
    "        except:\n",
    "             print('No such word in vocabulary')\n",
    "        finally:\n",
    "            while itinerary[-1].shape[0]<spotsPerDay:\n",
    "                Filter=df_spot['chosen']==False\n",
    "                spot=getSpot(df_spot.loc[Filter,:])\n",
    "                df_spot.loc[df_spot.name==spot,'chosen']=True\n",
    "                itinerary[-1]=itinerary[-1].append(df_spot.loc[df_spot.name==spot])\n",
    "\n",
    "    # random            \n",
    "    for i in range(userdata['howlong']-2):\n",
    "        Filter=df_spot['chosen']==False\n",
    "        spot=getSpot(df_spot.loc[Filter,:].sort_values('score').head(10))\n",
    "        interesting_word=spot.split(' ')[0]\n",
    "        df_spot.loc[df_spot['name']==spot,'chosen']=True\n",
    "        itinerary.append(df_spot.loc[df_spot['name']==spot,:])\n",
    "        try:\n",
    "            related_spot=[]\n",
    "            for word in model.wv.similar_by_word(interesting_word,100):\n",
    "                if 'N' in pos[word[0]] or 'n' in pos[word[0]]:\n",
    "                    if word[1]>0.65:\n",
    "                        if word[0] in synonym.keys():\n",
    "                            related_spot.append(synonym[word[0]])\n",
    "                        else:\n",
    "                            related_spot.append(word[0])\n",
    "    #         print(related_spot)\n",
    "            for rs in related_spot:\n",
    "                searchbool=df_spot['name'].apply(lambda s: True if rs in s else False)\n",
    "                chosen=df_spot.loc[searchbool & (df_spot['chosen']==False),'name'].to_numpy()\n",
    "                if len(chosen)==0:\n",
    "                    continue\n",
    "                df_spot.loc[df_spot['name']==chosen[0],'chosen']=True\n",
    "                tmp=df_spot.loc[df_spot['name']==chosen[0],:]\n",
    "\n",
    "                itinerary[-1]=itinerary[-1].append(tmp, ignore_index=True)\n",
    "                if itinerary[-1].shape[0]>=spotsPerDay:\n",
    "                    break\n",
    "        except:\n",
    "             print('No such word in vocabulary')\n",
    "        finally:\n",
    "            while itinerary[-1].shape[0]<spotsPerDay:\n",
    "                Filter=df_spot['chosen']==False\n",
    "                spot=getSpot(df_spot.loc[Filter,:])\n",
    "                df_spot.loc[df_spot.name==spot,'chosen']=True\n",
    "                itinerary[-1]=itinerary[-1].append(df_spot.loc[df_spot.name==spot])\n",
    "    \n",
    "    for i in range(len(itinerary)):\n",
    "        itinerary[i]=itinerary[i].to_json(force_ascii=False,orient='records')\n",
    "    return flask.jsonify(itinerary)\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    ############## pre-load ###############\n",
    "    with open('POS.dat', 'rb') as file:\n",
    "        pos=pickle.load(file)\n",
    "\n",
    "    with open('synonym.dat', 'rb') as file:\n",
    "        synonym=pickle.load(file)\n",
    "\n",
    "    model = word2vec.Word2Vec.load(\"word2vec.model\")\n",
    "\n",
    "    weight_spot=pd.read_csv('weight.csv')\n",
    "    weight_spot=weight_spot.iloc[:,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,15,16,17,24,26,27,28,29,31]]\n",
    "    weight_spot.columns=['label','淺草','迪士尼','晴空塔','東京鐵塔',\n",
    "                     '秋葉原','明治神宮','築地外圍海鮮市場','豐洲市場',\n",
    "                     '原宿竹下通','台場','大江戶物語','六本木之丘展望台',\n",
    "                     '新宿歌舞伎町','阿美橫丁','上野',\n",
    "                     '神田萬世橋','景點知名度','古蹟','購物',\n",
    "                     '自然景觀','民俗活動','表演']\n",
    "\n",
    "    clf = joblib.load('spot_clf.joblib')\n",
    "\n",
    "    app.run(port=5007)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
